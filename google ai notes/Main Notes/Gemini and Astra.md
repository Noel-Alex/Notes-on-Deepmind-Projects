
28-10-2024 15:09

Status: under work

Tags: [[Gemini]] [[Ai]] [[LLM-LLVM]] [[google]] 


# Introduction to Gemini
Google's **Gemini AI** is a versatile, [multimodal](Terms#Multimodal) model developed by DeepMind, which can process text, images, audio, and video, making it particularly powerful for applications requiring cross-modal reasoning and complex analysis. Designed with scalability in mind, Gemini offers versions that run on various devices, from mobile (Gemini Nano) to high-performance data centers (Gemini Ultra). The architecture of Gemini leverages Google's TPU (Tensor Processing Unit) infrastructure, specifically TPU v4 and the latest v5e systems, ensuring efficient large-scale training and rapid inference capabilities.

One of the standout features of Gemini is its advanced reasoning and planning ability, with Gemini Pro, for instance, capable of handling extensive data, such as up to 2,000 pages of text, or video and audio spanning several hours. This proficiency is integrated into several Google products, like **Bard** and **Pixel devices**, enhancing real-time functionalities such as advanced summarization, smart replies, and Search Generative Experiences (SGE).

Gemini was designed to support both foundational and applied AI tasks, with configurable safety and moderation features, JSON-based structured data support, and function calling—making it adaptable for a wide range of applications. In its upcoming updates, Gemini is set to power more Google services, broadening the scope for user assistance in everyday tasks and professional settings alike.

For technical deep dives, Google has released Gemini’s specifications and functionality through platforms like AI Studio, where developers can experiment and deploy it in customized use cases, exploring its multimodal capabilities across real-world scenarios.
![[Pasted image 20241028164748.png]]


Gemini isn't just a single model but a whole family of models of varying sizes that serve different purposes and as [multimodal](Terms#Multimodal) models they can take in inputs from text as well as audio, image, etc. These are advanced models that build on top of the [GPT](GPT%20Notes) mentioned in the Attention is all you need paper with many changes to improve output quality, increase context window size (of which Gemini boasts the largest for any LLM with inputs capable of being 10 million tokens long for it's largest models in research) and also to introduce multimodal capabilities.

![[Pasted image 20241028163759.png]]
though Gemini's architecture isn't available to the public, this is a comparison to the Initial Transformer model proposed by the Attention is all you need paper and the architecture used by LLaMA which is currently the best performing open source model available
[***Link to the paper detailing everything about the development of LLaMA 3**](https://scontent.fruh4-5.fna.fbcdn.net/v/t39.2365-6/463020162_522238820565582_8192401983671993921_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=KrU4g2zLqN0Q7kNvgHHyDqw&_nc_zt=14&_nc_ht=scontent.fruh4-5.fna&_nc_gid=AMHydSWmz_87tlZSFiA_1Ov&oh=00_AYB29c_heJvEejXKDu9M9TeVTpxF8tFvvBarVESVQCnRvw&oe=67257C99)


# Astra
Building on the Gemini models, Project Astra explores the future of AI assistants that can process multimodal information, understand the context you’re in, and respond naturally in conversation.

To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do — and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.

"While we’ve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge.

Over the past few years, we've been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural."

Project Astra revolves around using [AI agents](Terms#AI%20Agents%20(LLMs)) that can carry out tasks as required by the user, aided by generative AI. 

Gemini uses [Imagen](Imagen) for it's image generation related tasks, 
![[Pasted image 20241028164149.png]]
*image generated by Gemini when asked to show its architecture*


# Gemmas
Although 

# References