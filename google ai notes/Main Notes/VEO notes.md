
21-10-2024 19:24

Status: under progress

Tags: [[veo]] [[google]] [[Ai]] [[text to video]]


# VEO
>To produce a coherent scene, generative video models need to accurately interpret a text prompt and combine this information with relevant visual references.


## Purpose
With advanced understanding of natural language and visual semantics, Veo generates video that closely follows the prompt. It accurately captures the nuance and tone in a phrase, rendering intricate details within complex scenes.

When given both an input video and editing command, like adding kayaks to an aerial shot of a coastline, Veo can apply this command to the initial video and create a new, edited video.

Veo can also generate a video with an image as input along with the text prompt. By providing a reference image in combination with a text prompt, it conditions Veo to generate a video that follows the image’s style and user prompt’s instructions.

The model is also able to generate videos and extend them to 60 seconds and beyond, either from a single prompt, or a sequence of prompts which together help describe a story.

## Consistency across frames
Maintaining visual consistency can be a challenge for video generation models. Characters, objects, or even entire scenes can flicker, jump, or morph unexpectedly between frames, disrupting the viewing experience.

Veo's cutting-edge latent diffusion transformers reduce the appearance of these inconsistencies, keeping characters, objects and styles in place, as they would in real life.
# References
[veo page](https://deepmind.google/technologies/veo/#:~:text=Veo%20is%20our%20most%20capable,video%20generation%20model%20to%20date.)
